{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Search and Analyze with Open Collections API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and setup all the things (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, requests, math, re, string, nltk\n",
    "\n",
    "# allow matplotlib to run in-line\n",
    "% matplotlib inline \n",
    "\n",
    "nltk.download(\"punkt\") # Word tokenizer\n",
    "nltk.download(\"stopwords\") # Stop words\n",
    "from nltk import word_tokenize\n",
    "\n",
    "ocUrl = 'https://open.library.ubc.ca/'\n",
    "ocApiUrl = 'https://oc-index.library.ubc.ca' # APPY URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set our API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get your own API key at https://open.library.ubc.ca/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apiKey = 'ac40e6c2cb345593ed1691e0a8b601bba398e42d85f81f893c5ab709cec63c6c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '\"Master of Journalism\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Available repositories__\n",
    "\n",
    "* __oc__ - all repositories\n",
    "* __dsp__ - only DSpace / cIRcle\n",
    "* __cdm__ - only ContentDM\n",
    "* __atm__ - only AtoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repo = 'dsp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://open.library.ubc.ca/research to build a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = dict()\n",
    "\n",
    "search['from'] = 0\n",
    "search['size'] = 10\n",
    "search['type'] = 'object'\n",
    "search['body'] = dict()\n",
    "\n",
    "# Sort settings\n",
    "search['body']['sort'] = dict()\n",
    "search['body']['sort']['_score'] = dict()\n",
    "search['body']['sort']['_score']['order'] = 'desc'\n",
    "\n",
    "# Fields to return\n",
    "search['body']['fields'] = []\n",
    "search['body']['fields'].append('title')\n",
    "search['body']['fields'].append('ubc.transcript')\n",
    "search['body']['fields'].append('description')\n",
    "search['body']['fields'].append('ubc.internal.provenance.nick')\n",
    "\n",
    "# Query String\n",
    "search['body']['query'] = dict()\n",
    "search['body']['query']['query_string'] = dict()\n",
    "search['body']['query']['query_string']['query'] = query\n",
    "\n",
    "#Set the repo\n",
    "search['index'] = repo\n",
    "\n",
    "jsonSearch = json.JSONEncoder(search)\n",
    "\n",
    "print(json.dumps(search, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchUrl = ocApiUrl+'/search?apiKey='+apiKey\n",
    "apiResponse = requests.post(searchUrl, json=search).json()\n",
    "\n",
    "print(json.dumps(apiResponse, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get just the Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apiItems = apiResponse['data']['data']['hits']['hits']\n",
    "print(apiItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse items and clean full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = []\n",
    "for apiItem in apiItems:\n",
    "    item = dict()\n",
    "    item['id'] = apiItem['_id']\n",
    "    item['title'] = apiItem['fields']['title'][0]\n",
    "    item['description'] = apiItem['fields']['description'][0]\n",
    "    item['collection'] = apiItem['fields']['ubc.internal.provenance.nick'][0]\n",
    "    \n",
    "    # Clean Full Text\n",
    "    cleanFullText = apiItem['fields']['ubc.transcript'][0].lower()\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    cleanFullText = pattern.sub(' ', cleanFullText)\n",
    "    \n",
    "    item['fullText'] = cleanFullText\n",
    "    item['words'] = word_tokenize(cleanFullText)\n",
    "    items.append(item)\n",
    "    \n",
    "print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item with most words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostWords = 0\n",
    "winner = 0\n",
    "for key, item in enumerate(items):\n",
    "    if(len(item['words']) > mostWords):\n",
    "        mostWords = len(item['words'])\n",
    "        winner = key\n",
    "\n",
    "print(\"Winner is \"+ocUrl+'collections/'+items[winner]['collection']+'/items/'+items[winner]['id'] + \n",
    "      \" with \"+str(mostWords)+ \" words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item with most unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostWords = 0\n",
    "winner = 0\n",
    "for key, item in enumerate(items):\n",
    "    if(len(set(item['words'])) > mostWords):\n",
    "        mostWords = len(set(item['words']))\n",
    "        winner = key\n",
    "\n",
    "print(\"Winner is \"+ocUrl+'collections/'+items[winner]['collection']+'/items/'+items[winner]['id'] + \n",
    "      \" with \"+str(mostWords)+ \" unique words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Richest in vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate the lexical richness of a text. For example, by dividing the total number of words by the number of unique words, we can see the average number of times each word is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrScore = 0\n",
    "winner = 0\n",
    "for key, item in enumerate(items):\n",
    "    if(len(item['words'])/len(set(item['words'])) > lrScore):\n",
    "        lrScore = round(len(item['words'])/len(set(item['words'])))\n",
    "        winner = key\n",
    "\n",
    "print(ocUrl+'collections/'+items[winner]['collection']+'/items/'+items[winner]['id'] + \n",
    "      \" \\nis the richest in vocabulary with each word being used an average of \"+str(lrScore)+ \" times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allWords = []\n",
    "for item in items:\n",
    "    allWords += item['words']\n",
    "print(str(len(allWords)) + \" words in total\")\n",
    "# print(allWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching within the full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = \"truth\"\n",
    "# search = \"the\"\n",
    "text = nltk.Text(allWords)\n",
    "text.count(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of full text that the search takes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "100.0*allWords.count(search)/len(allWords) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance search on the full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text.concordance(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical dispersion of search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "text.dispersion_plot([search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words used similarly to our search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search ='government'\n",
    "text.similar(search) # How does this work? Magic obviously!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(items[0]['words'])\n",
    "finder.apply_freq_filter(3)\n",
    "sorted(finder.nbest(bigram_measures.pmi, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = items[0]['words']\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "# Permit 'and' to appear in the middle of a trigram, but not on either edge:\n",
    "finder.apply_ngram_filter(lambda w1, w2, w3: 'and' in (w1, w3))\n",
    "# score trigram based on frequency\n",
    "scored = finder.score_ngrams(trigram_measures.raw_freq)\n",
    "sorted(finder.nbest(trigram_measures.raw_freq, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
